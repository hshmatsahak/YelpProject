{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Yelp Further Architecture Exploration (OLD).ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["NOTE: ARCHITECTURES ARE PRELIMINARY AND HAVEN'T BEEN DEBUGGED FOR LAYER INPUT/OUTPUT INCONSISTENCIES\n","\n","IN OTHER WORDS: **THIS SPECIFIC NOTEBOOK IS NOT COMPLETE. DO NOT REFER TO IT.**"],"metadata":{"id":"LfmqswEtb_fs"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"DkxSDBRRfpP2"},"outputs":[],"source":["import numpy as np                  # just in case\n","import pandas as pd                 # for extracting info\n","\n","import torch                        \n","import torch.nn as nn               \n","import torch.nn.functional as F\n","from torchsummary import summary        "]},{"cell_type":"code","source":["# global variables and parameters \n","img_size = 256              # assuming square images -> subject to change\n","img_channels = 3           # assuming RGB images \n","num_outputs = 1             # we want a single number signifying the rating"],"metadata":{"id":"3CJRwmrAmEDq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data Imports"],"metadata":{"id":"Uza3SXZIG8QV"}},{"cell_type":"markdown","source":["The Yelp Database (uploaded to Drive) is extracted to a pandas dataframe for input into the proposed neural networks shown below."],"metadata":{"id":"rW5yMOIFG-os"}},{"cell_type":"code","source":[""],"metadata":{"id":"Ft3IDEqrHGzx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# A Simple CNN"],"metadata":{"id":"F4Gn07RPiIpV"}},{"cell_type":"markdown","source":["## Architecture"],"metadata":{"id":"xbedzYSlCkjZ"}},{"cell_type":"code","source":["conv_kernel_size = 3        \n","pool_kernel_size = 4"],"metadata":{"id":"EisrRq6iC30n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# as a preliminary, we start with a super-basic CNN with pooling \n","class SimpleCNN(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.conv1 = nn.Conv2d(img_channels, 8, conv_kernel_size)\n","        self.pool1 = nn.MaxPool2d(pool_kernel_size)\n","        self.conv2 = nn.Conv2d(8, 16, conv_kernel_size)\n","        self.pool2 = nn.MaxPool2d(pool_kernel_size)\n","        self.fc1 = nn.Linear(16*(256/pool_kernel_size**2)**2, 64)\n","        self.fc2 = nn.Linear(64, 1)\n","\n","    def forward(self, x):\n","        x = self.pool1(F.relu(self.conv1(x)))       # each conv layer consists of convolution -> activation func -> pooling\n","        x = self.pool2(F.relu(self.conv2(x)))\n","        x = torch.flatten(x, 1)                     # to feed into linear layers\n","        x = self.fc1(x)\n","        x = self.fc2(x)             \n","\n","        return x        # no non-linearity applied since we want lin. regression"],"metadata":{"id":"mOg9kUHhiTiw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Training"],"metadata":{"id":"KcEd33eXCF6x"}},{"cell_type":"code","source":[""],"metadata":{"id":"BRCSVKdnCFZI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# CNN + Dropout"],"metadata":{"id":"9YPnRZtvC_LS"}},{"cell_type":"markdown","source":["## Architecture"],"metadata":{"id":"dAHIHNLDDNbB"}},{"cell_type":"code","source":["dropout_rate_1 = 0.2\n","dropout_rate_2 = 0.4\n","pool_kernel_size = 2"],"metadata":{"id":"YF29lVCuDMfV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# borrowing from a pytorch tutorial + modifying to get a single linear output\n","class DropoutCNN(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.conv1 = nn.Conv2d(img_channels, 8, conv_kernel_size)\n","        self.conv2 = nn.Conv2d(8, 16, conv_kernel_size)\n","        self.dropout1 = nn.Dropout2d(dropout_rate_1)\n","        self.dropout2 = nn.Dropout2d(dropout_rate_2)\n","        self.pool1 = nn.MaxPool2d(pool_kernel_size)\n","        self.fc1 = nn.Linear(16*(256/pool_kernel_size)**2, 64)\n","        self.fc2 = nn.Linear(64, 1)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = F.relu(x)\n","\n","        x = self.conv2(x)\n","        x = F.relu(x)\n","\n","        x = F.max_pool2d(x, 2)\n","        x = self.dropout1(x)\n","\n","        x = torch.flatten(x, 1)\n","\n","        x = self.fc1(x)\n","        x = F.relu(x)\n","        x = self.dropout2(x)\n","        x = self.fc2(x)\n","\n","        return x"],"metadata":{"id":"WzSKriYGDVO8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Pretrained Model Performance"],"metadata":{"id":"8dJ4z8fRCXkJ"}},{"cell_type":"markdown","source":[""],"metadata":{"id":"BWjsWh0EDEo-"}},{"cell_type":"markdown","source":["## Class Setup"],"metadata":{"id":"NgpmoYk1CqcR"}},{"cell_type":"code","source":[""],"metadata":{"id":"_JUTAlx2Cg2Y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Training"],"metadata":{"id":"nXhxl-RtCsip"}},{"cell_type":"markdown","source":["# Custom Embedding CNN"],"metadata":{"id":"SlqPnylTGyFk"}},{"cell_type":"markdown","source":["This notebook defines the components of a custom CNN architecture inspired by the semantic embedding to review prediction pipeline detailed by Tang et. al. (https://www.ijcai.org/Proceedings/15/Papers/193.pdf)"],"metadata":{"id":"dGsqHv6Efz52"}}]}